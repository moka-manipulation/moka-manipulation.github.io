<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="MOKA: Open-World Robotic Manipulation through Mark-Based Visual Prompting">
  <meta name="keywords" content="Visual Prompting, GPT4V">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>MOKA: Open-World Robotic Manipulation through Mark-Based Visual Prompting</title>
	<link rel="icon" type="image/png" href="images/moka_icon.png"/>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <!-- <div class="container is-fullhd"> -->
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title"><a target="_blank" style="color: black" href="https://www.roboticsproceedings.org/rss20/p062.html">MOKA: Open-World Robotic Manipulation through Mark-Based Visual Prompting</a></h1>

          <h3 class="title is-4 conference-authors"><a target="_blank" style="color: #8C1515" href="https://www.roboticsproceedings.org/rss20/p062.html">Robotics: Science and Systems (RSS) 2024</a></h3>

          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://kuanfang.github.io">Kuan Fang*</a></span>,
            <span class="author-block">
              <a href="https://fangchenliu.github.io">Fangchen Liu*</a></span>,
            <span class="author-block">
              <a href="https://people.eecs.berkeley.edu/~pabbeel/">Pieter Abbeel</a>,
            </span>
            <span class="author-block">
              <a href="https://people.eecs.berkeley.edu/~svlevine/">Sergey Levine</a>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>*</sup> denotes equal contribution, alphabetical order</span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block">Berkeley AI Research, UC Berkeley</span>
          </div>


          <div class="column has-text-centered">
            <div class="publication-links">

              <!-- PDF Link. -->
              <span class="link-block">
                <a target="_blank" href="https://www.roboticsproceedings.org/rss20/p062.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- arXiv Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2403.03174"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://youtu.be/L571UpVYenE"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/moka-manipulation/moka"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-fullhd">
    <div class="hero-body">
      <div class="container">
        <div class="columns is-vcentered  is-centered">
          <video id="teaser" autoplay muted loop height="70%" width="70%">
            <source src="videos/teaser.mp4"
                    type="video/mp4">
          </video>
          </br>
        </div>
        <h2 class="subtitle has-text-justified">
        <b>MOKA</b> employs pre-trained vision-language models (GPT-4V) to predict <b>point-based affordance representations</b> for solving manipulation tasks in zero- or few-shot manners. By <b>annotating marks</b> (candidate points, grids, and captions) on RGB images, MOKA converts the motion generation problem into a series of visual question-answering problems that the VLM can address.
        </h2>
      </div>
    </div>
  </div>
</section>

<hr>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="my-block">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
            Open-world generalization requires robotic systems to have a profound understanding of the physical world and the user command to solve diverse and complex tasks. While the recent advancement in vision-language models (VLMs) has offered unprecedented opportunities to solve open-world problems, how to leverage their capabilities to control robots remains a grand challenge. In this paper, we introduce Marking Open-world Keypoint Affordances (MOKA), an approach that employs VLMs to solve robotic manipulation tasks specified by free-form language instructions. Central to our approach is a compact point-based representation of affordance, which bridges the VLM’s predictions on observed images and the robot’s actions in the physical world. By prompting the pre-trained VLM, our approach utilizes the VLM’s commonsense knowledge and concept understanding acquired from broad data sources to predict affordances and generate motions. To facilitate the VLM’s reasoning in zero-shot and few-shot manners, we propose a visual prompting technique that annotates marks on images, converting affordance reasoning into a series of visual question-answering problems that are solvable by the VLM. We further explore methods to enhance performance with robot experiences collected by MOKA through in-context learning and policy distillation. We evaluate and analyze MOKA’s performance on various table-top manipulation tasks including tool use, deformable body manipulation, and object rearrangement.
            </p>
          </div>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>

  <div class="container is-fullhd">
    <div class="my-block">
      <!-- <div class="columns is-centered has-text-centered"> -->
        <div class="column is-full-width">
          <h2 class="title is-3">Marking Open-world Keypoint Affordances (MOKA)</h2>

          <h2 class="content has-text-justified">
            MOKA employs VLMs in a <b>hierarchical visual prompting</b> framework, which converts the affordance reasoning problem into a series of visual question problems that are feasible for the VLM to address.
          </h2>

          <div>
            <img src="images/model.png"
                       class="interpolation-image"
                       alt="Interpolation end reference image."/>
          </div>

          <h2 class="content has-text-justified">
						On the <b>high level</b>, the VLM is prompted to decompose the free-form language description of the task into a sequence of subtasks and summarize the subtask information. 
						<!-- </br> -->
						On the <b>low level</b>, the VLM produces the point-based affordance representation based on the marked image. 
          </h2>

        <!-- </div> -->
      </div>
    </div>

    <div class="my-block">
      <!-- <div class="columns is-centered has-text-centered"> -->
        <div class="column is-full-width">
          <h2 class="title is-3">Point-based Affordance Representations</h2>
          <h2 class="content has-text-justified">
            To bridge the VLM’s predictions on 2D images and the robot’s motion in the physical world, we introduce a point-based affordance representation. Using a set of keypoints and waypoints, we can specify the robot’s motions for a wide range of tasks. 
          </h2>
          <div>
          <img src="images/affordances.png"
                     class="interpolation-image"
                     alt="Interpolation end reference image."
                     />
          </div>
        </div>
      <!-- </div> -->
    </div>

    <!-- <div class="container is-max-widescreen"> -->
    <div class="my-block">
    <!-- <div class="container is-fullhd"> -->

      <!-- <div class="rows"> -->
      <!-- <div class="container is-fullhd"> -->
      <div class="rows is-fullhd">
        <!-- <div class="column has-text-centered"> -->
        <h2 class="title is-3">Tasks</h2>
        
        <p class="content has-text-justified">
          Given free-form descriptions of the tasks, MOKA can effectively predict the point-based affordance representations and generates the desired motions.
        </p>
        
        <div class="rows">
          <div class="columns">
            <div class="column has-text-justified">
              <video id="dist1" controls="" muted="" autoplay="" loop="" width="99%">
                <source src="videos/moka_task_0_0.mp4" type="video/mp4">
              </video>
              <p style="text-align:left">
                "Move the eyeglasses onto the yellow cloth and use the brush to sweep the snack package to the right side of the table."
              </p>
              <p style="text-align:center">
								(Subtask 1)
              </p>
            </div>
        
            <div class="column has-text-centered">
              <video id="dist2" controls="" muted="" autoplay="" loop="" width="99%">
                <source src="videos/moka_task_1_0.mp4" type="video/mp4">
              </video>
              <p style="text-align:left">
                "Use the ultrasound cleaner to clean the metal watch. The unstrasound cleaner has no lid and can be turned on by pressing the red button."
              </p>
              <p style="text-align:center">
								(Subtask 1)
              </p>
            </div>
        
            <div class="column has-text-centered">
              <video id="dist2" controls="" muted="" autoplay="" loop="" width="99%">
                <source src="videos/moka_task_a0.mp4" type="video/mp4">
              </video>
              <p style="text-align:left">
                "Close the drawer."
              </p>
            </div>
          </div>

          <div class="columns">
            <div class="column has-text-centered">
              <video id="dist1" controls="" muted="" autoplay="" loop="" width="99%">
                <source src="videos/moka_task_0_1.mp4" type="video/mp4">
              </video>
              <p style="text-align:left">
                "Move the eyeglasses onto the yellow cloth and use the brush to sweep the snack package to the right side of the table."
              </p>
              <p style="text-align:center">
								(Subtask 2)
              </p>
            </div>
        
            <div class="column has-text-centered">
              <video id="dist2" controls="" muted="" autoplay="" loop="" width="99%">
                <source src="videos/moka_task_1_1.mp4" type="video/mp4">
              </video>
              <p style="text-align:left">
                "Use the ultrasound cleaner to clean the metal watch. The unstrasound cleaner has no lid and can be turned on by pressing the red button."
              </p>
              <p style="text-align:center">
								(Subtask 2)
              </p>
            </div>
        
            <div class="column has-text-centered">
              <video id="dist2" controls="" muted="" autoplay="" loop="" width="99%">
                <source src="videos/moka_task_a1.mp4" type="video/mp4">
              </video>
              <p style="text-align:left">
                "Insert the pink roses into the vase."
              </p>
            </div>
          </div>

        <div class="rows">
          <div class="columns">
            <div class="column has-text-centered">
              <video id="dist1" controls="" muted="" autoplay="" loop="" width="99%">
                <source src="videos/moka_task_2_0.mp4" type="video/mp4">
              </video>
              <p style="text-align:left">
                "Make a gift box containing the perfurme bottle. Put some golden filler beneath the perfume."
              </p>
              <p style="text-align:center">
								(Subtask 1)
              </p>
            </div>
        
            <div class="column has-text-centered">
              <video id="dist2" controls="" muted="" autoplay="" loop="" width="99%">
                <source src="videos/moka_task_3_0.mp4" type="video/mp4">
              </video>
              <p style="text-align:left">
                "Unplug the charge cable and close the lid of the laptop."
              </p>
              <p style="text-align:center">
								(Subtask 1)
              </p>
            </div>
        
            <div class="column has-text-centered">
              <video id="dist2" controls="" muted="" autoplay="" loop="" width="99%">
                <source src="videos/moka_task_a2.mp4" type="video/mp4">
              </video>
              <p style="text-align:left">
                "Use the fur remover to remove the white fur ball on the sweater."
              </p>
            </div>
          </div>

          <div class="columns">
            <div class="column has-text-centered">
              <video id="dist1" controls="" muted="" autoplay="" loop="" width="99%">
                <source src="videos/moka_task_2_1.mp4" type="video/mp4">
              </video>
              <p style="text-align:left">
                "Make a gift box containing the perfurme bottle. Put some golden filler beneath the perfume."
              </p>
              <p style="text-align:center">
								(Subtask 2)
              </p>
            </div>
        
            <div class="column has-text-centered">
              <video id="dist2" controls="" muted="" autoplay="" loop="" width="99%">
                <source src="videos/moka_task_3_1.mp4" type="video/mp4">
              </video>
              <p style="text-align:left">
                "Unplug the charge cable and close the lid of the laptop."
              </p>
              <p style="text-align:center">
								(Subtask 2)
              </p>
            </div>
        
            <div class="column has-text-centered">
              <video id="dist2" controls="" muted="" autoplay="" loop="" width="99%">
                <source src="videos/moka_task_a3.mp4" type="video/mp4">
              </video>
              <p style="text-align:left">
                "Put the scissors in the hand."
              </p>
            </div>
          </div>

        </div>

      </div>
    </div>

		</br>
		</br>

    <div class="my-block">
        <div class="column is-full-width">
          <h2 class="title is-3">Robustness Analysis</h2>
          <div>
          <h2 class="content has-text-justified">
            For the same task, MOKA's prediction is robust to variations of instructions, objects, and initial poses. Each column in the image uses the same language instruction and similar initial arrangements of objects. The two rows involve different objects.
          </h2>

          <div class="rows">
            <div class="columns">
              <div class="column has-text-centered">
                <img src="images/robustness.png"
                     class="interpolation-image"
                     alt="Interpolation end reference image."
                     width="380px"
                />
              </div>
              <div class="column has-text-centered">
                <img src="images/robustness.png"
                     class="interpolation-image"
                     alt="Interpolation end reference image."
                     width="380px"
                />
              </div>
              <div class="column has-text-centered">
                <img src="images/robustness.png"
                     class="interpolation-image"
                     alt="Interpolation end reference image."
                     width="380px"
                />
              </div>
						</div>
					</div>
    </div>

    </br>
    </br>
    </br>
    </br>

    <div>
      <div class="container is-max-widescreen content">
        <h2 class="title">BibTeX</h2>
        <pre><code>@article{fangandliu2024moka,
      title={MOKA: Open-World Robotic Manipulation through Mark-Based Visual Prompting},
      author={Kuan Fang and Fangchen Liu and Pieter Abbeel and Sergey Levine},
      journal={Robotics: Science and Systems (RSS)},
      year={2024}
  }</code></pre>
      </div>
    </div>
  </div>

</section>

<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website was adapted from nerfie's <a href="https://github.com/nerfies/nerfies.github.io">source code</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
